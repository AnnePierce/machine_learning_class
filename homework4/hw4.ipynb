{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSBC5180 HW4: Sentiment Classification \n",
    "\n",
    "### Solution by: Anne Pierce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will classify the *sentiment* (positive, negative, or neutral) of hotel reviews posted on Yelp. See Chapter 8 of the textbook for more explanation of sentiment classification. The main goal of this assignment is to get practice with feature engineering, feature extraction, and feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to Hand In\n",
    "You will turn in a completed notebook on Canvas as a ipynb file. Your submission should be contained in a single Jupyter notebook named `hw4-firtname-lastname.ipynb`, where `firstname` and `lastname` are replaced with your first and last names. This will include your code as well as figures and answers to questions. Please create headers for your cells that are labeled “Deliverable” followed by the problem number, so that your responses are easy to find.\n",
    "\n",
    "## The Associated Quiz\n",
    "You will complete the associated quiz for HW4 on Canvas. The quiz is name **\"Quiz HW4 \"**.\n",
    "\n",
    "## Collaboration policies\n",
    "You are allowed to work with up to 3 people besides yourself. You are still expected to write up your own solution. Each individual must turn in their own submission, and list your collaborators after your name.\n",
    "\n",
    "## Asking for Help\n",
    "You are encouraged to ask questions on the Zoom channel. Do not post anything that you are turning in. In this assignment, that would be any of the plots you need to hand in, or the parameter values. However, you can describe your results, like the number of iterations it took to converge, and general things you observe about the algorithms.\n",
    "You may ask questions to help with debugging, but do not post your code in a way of giving away solution. You can share error messages and describe what you are trying to do with your code, but try not to write enough to “give away” the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotated data\n",
    "\n",
    "The dataset contains 1,000 reviews of hotels downloaded from Yelp. Sentiment labels could be one of three classes (positive, negative, neutral). Each review is labeled as:\n",
    "\n",
    "- **1:** The review expresses a *positive* opinion toward the hotel.\n",
    "- **0:** The review expresses a mixed or neutral opinion toward the hotel.\n",
    "- **-1:** The review expresses a *negative* opinion toward the hotel.\n",
    "\n",
    "In this assignment, you will build classifiers to predict these three classes. The dataset has been prepared for you. A random subset (approximately 10% of the reviews) was selected as test data, while the rest will be used for training. Run the code below to download and extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('yelp_hotels1000.csv', \n",
    "                 header=None, encoding='ISO-8859-1')\n",
    "\n",
    "df_train = df.loc[df[1] == 'train']\n",
    "df_test = df.loc[df[1] == 'test']\n",
    "\n",
    "Y_train = df_train.iloc[0:, 2].values\n",
    "text_train = df_train.iloc[0:, 3].values\n",
    "\n",
    "Y_test = df_test.iloc[0:, 2].values\n",
    "text_test = df_test.iloc[0:, 3].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the classifier\n",
    "\n",
    "### Tokenization and feature extraction\n",
    "\n",
    "The first step is to convert the raw text into feature vectors. In Ch. 8 of the book, and in HW2, the class [`CountVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) is presented as a way to convert text strings into `sklearn` feature vectors. This class can automatically perform tokenization (doing preprocessing steps we talked about in class, including lowercasing and stripping punctuation). However, for this assignment, we aren't going to use `CountVectorizer`, though it is useful to know about. We will instead write our own code to do tokenization and feature extraction. This will allow us to modify the features, which you will need to do later, plus it will let you see how feature extraction is done.\n",
    "\n",
    "The code below defines our feature extraction function, `features`. It takes a text string and it outputs a Python dictionary where the keys are the feature names and the values are the feature values. This is a _sparse_ representation, meaning it only outputs features with nonzero value.\n",
    "\n",
    "By default, the features extracted by this function are n-gram counts. The keyword argument `ngram_range` specifies the length of n-grams to extract. This argument should be a pair of integers, where the first integer is the lower end of the length to be extracted and the second integer is the upper end. For example, `ngram_range=(1,3)` will extract 1-grams, 2-grams, and 3-grams, while `ngram_range=(2,2)` will extract only 2-grams.\n",
    "\n",
    "The function performs two initial preprocessing steps: making the text lowercase (so different capitalizations of words will map to the same feature), and removing consecutive characters that are repeated more than twice (e.g., \"woooow\" and \"wooooooooow\" will both map to simply \"woow\" rather than being counted as separate words).\n",
    "\n",
    "The function tokenizes words as follows. First, non-alphanumeric characters are replaced with whitespace, then strings separated by whitespace are treated as tokens. Python's `split` function converts a string into a list of tokens that were separated by whitespace. The list of tokens is passed to the `ngrams` function, defined below, which returns a list of all n-grams of length `n` contained in the list. Finally, the function also pulls out tokens containing anything _but_ alphanumeric characters. This will capture punctuation marks and emojis, which may also be useful for classification. These are treated as unigram features rather than longer sequences.\n",
    "\n",
    "For now, simply run the code below. However, you'll need to modify this code later, so you need to understand what it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def ngrams(tokens, n):\n",
    "    output = []\n",
    "    for i in range(n-1, len(tokens)):\n",
    "        ngram = ' '.join(tokens[i-n+1:i+1])\n",
    "        output.append(ngram)\n",
    "    return output\n",
    "\n",
    "def features(text, ngram_range=(1,1)):\n",
    "    text = text.lower()      # make the string lowercase\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)     # remove consecutive characters that are repeated more than twice\n",
    "    \n",
    "    features_in_text = []   # running list of all features in this instance (can be repeated)\n",
    "    \n",
    "    # treat alphanumeric characters as word tokens (removing anything else),\n",
    "    # and extract all n-grams of length n specified by ngram_range\n",
    "    \n",
    "    text_alphanum = re.sub('[^a-z0-9]', ' ', text)\n",
    "    for n in range(ngram_range[0], ngram_range[1]+1):\n",
    "        features_in_text += ngrams(text_alphanum.split(), n)\n",
    "    \n",
    "    # now treat punctuation as word tokens, and get their counts (only unigrams)\n",
    "    \n",
    "    text_punc = re.sub('[a-z0-9]', ' ', text)\n",
    "    features_in_text += ngrams(text_punc.split(), 1)\n",
    "    \n",
    "    # 'Counter' converts a list into a dictionary whose keys are the list elements \n",
    "    #  and the values are the number of times each element appeared in the list\n",
    "    \n",
    "    return Counter(features_in_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better understanding of what the `features` function is returning, see what happens on the example text when you run the code below. The `ngram_range` is set to `(1,2)` which means it will extract both 1-grams and 2-grams. You should notice that it extracts all words (separated by punctuation) and two-word phrases, with counts based on how often they appear (e.g., \"`a sentence`\" is a 2-gram that appears twice). Also note that punctuation is also counted (but only as 1-grams, not 2-grams), and notice that \"`!!`\" has a count of 2 because \"!!!\" was rewritten as \"!!\".\n",
    "\n",
    "You may find it helpful to change the text and/or the n-gram range to see what features are extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is an example of a sentence to tokenize   actually  it s more than a sentence  it s two sentences  \n",
      "Counter({'a': 2, 'sentence': 2, 'it': 2, 's': 2, 'a sentence': 2, 'it s': 2, '!!': 2, ',': 2, \"'\": 2, 'this': 1, 'is': 1, 'an': 1, 'example': 1, 'of': 1, 'to': 1, 'tokenize': 1, 'actually': 1, 'more': 1, 'than': 1, 'two': 1, 'sentences': 1, 'this is': 1, 'is an': 1, 'an example': 1, 'example of': 1, 'of a': 1, 'sentence to': 1, 'to tokenize': 1, 'tokenize actually': 1, 'actually it': 1, 's more': 1, 'more than': 1, 'than a': 1, 'sentence it': 1, 's two': 1, 'two sentences': 1})\n"
     ]
    }
   ],
   "source": [
    "text = \"This is an example of a sentence to tokenize!! Actually, it's more than a sentence, it's two sentences!!!\"\n",
    "\n",
    "print(features(text, ngram_range=(1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to extract features from all of the training instances and convert them into a feature vector representation to be used by `sklearn`. The code below takes the output of the `features` function (with only 1-grams for this example, though you will change this later), then maps all the feature strings into integers, then defines `X_train` as a sparse array that encodes the values of each feature in each instance. Like in HW2, the [`DictVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) is used to do this conversion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vect = DictVectorizer()\n",
    "X_train = vect.fit_transform(features(d, ngram_range=(1,3)) for d in text_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier and hyperparameter tuning\n",
    "\n",
    "In this assignment, we will use multinomial logistic regression as our classifier. Recall that logistic regression outputs probabilities, and the multinomial version can handle more than two classes. Mulinomial logistic regression is also called a \"maximum entropy\" or \"MaxEnt\" classifier.\n",
    "\n",
    "We will use `sklearn`'s [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) class, setting the `multi_class` argument to `'multinomial'` which tells it to use the multinomial version (otherwise it defaults to binary logistic regression with a one-vs-rest scheme for multiclass data).\n",
    "\n",
    "The `LogisticRegression` class uses the argument `C` to denote the regularization strength (same as in the `SVC` class you used in HW3). It is important to adjust this hyperparameter to get good performance. We will tune this hyperparameter each time we build a classifier, using cross-validation for optimizing `C`. \n",
    "\n",
    "`sklearn` has a class, [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) for tuning a classifier with cross-validation. When you construct a `GridSearchCV` object, you supply the set of parameters and their possible values that you would like to adjust. During training, it will perform cross-validation with every combination of parameter values, then train a final classifier using the best-performing settings. In the code, only a small number of values are listed, because it would be too slow to try many combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cv': 3, 'error_score': nan, 'estimator__C': 1.0, 'estimator__class_weight': None, 'estimator__dual': False, 'estimator__fit_intercept': True, 'estimator__intercept_scaling': 1, 'estimator__l1_ratio': None, 'estimator__max_iter': 500, 'estimator__multi_class': 'multinomial', 'estimator__n_jobs': None, 'estimator__penalty': 'l2', 'estimator__random_state': 123, 'estimator__solver': 'lbfgs', 'estimator__tol': 0.01, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': LogisticRegression(max_iter=500, multi_class='multinomial', random_state=123,\n",
      "                   tol=0.01), 'n_jobs': None, 'param_grid': [{'C': [0.01, 0.1, 1.0]}], 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 0}\n",
      "Best parameter settings: {'C': 1.0}\n",
      "Validation accuracy: 0.730317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# this defines the classifier we will use -- don't change this variable\n",
    "\n",
    "base_classifier = LogisticRegression(multi_class='multinomial', solver='lbfgs', tol=1e-2, max_iter=500, random_state=123)\n",
    "\n",
    "# these are the C values we will compare -- don't change this variable\n",
    "\n",
    "params = [{'C': [0.01, 0.1, 1.0]}]\n",
    "\n",
    "# this performs 3-fold cross-validation with the above classifier and parameter options\n",
    "\n",
    "gs_classifier = GridSearchCV(base_classifier, params, cv=3)\n",
    "gs_classifier.fit(X_train, Y_train)\n",
    "\n",
    "print(gs_classifier.get_params())\n",
    "\n",
    "print(\"Best parameter settings:\", gs_classifier.best_params_)\n",
    "print(\"Validation accuracy: %0.6f\" % gs_classifier.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, calling `gs_classifier.fit` will perform cross-validation for all parameter settings. Once it finishes, then `gs_classifier` can be used as any other classifier object, so you can call the `predict` or `predict_proba` functions to make classifications, just as you did in HW3. As you can see in the code above, the object also contains variables that will give you the optimal parameters and cross-validation accuracy.\n",
    "\n",
    "Throughout this assignment, anytime you are asked to train a classifier, you should do so by calling `GridSearchCV(base_classifier, params, cv=3)` rather than directly calling the `LogisticRegression` class. Whenever you are asked for the cross-validation accuracy, this is given by the `best_score_` variable that you see above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Feature Choice and Selection\n",
    "\n",
    "We will begin by experimenting with different feature sets, where we modify the feature set in two ways. First, we will experiment with different sizes of n-grams. Second, we will experiment with automated feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram size\n",
    "\n",
    "As you saw above, the `features` function takes a keyword argument, `ngram_range`, that let's you specify the sizes of n-grams to extract. Experiment with six different ranges of n-gram sizes: (1,1), (2,2), (3,3), (1,2), (1,3), (2,3)\n",
    "\n",
    "For each n-gram range, you'll need to re-extract and vectorize the features (calling the `features` and `vect.fit_transform` functions, as done above). For each setting, calculate the cross-validation accuracy after using `GridSearchCV` to find the best $C$ value.\n",
    "\n",
    "#### Deliverable 1.1: Fill in the table below with the cross-validation accuracy when using each range of n-grams.\n",
    "\n",
    "| N-grams | Validation accuracy |\n",
    "|---------|---------------------|\n",
    "| (1,1)   |   0.753913          |\n",
    "| (2,2)   |   0.695502          |\n",
    "| (3,3)   |   0.619104          |\n",
    "| (1,2)   |   0.742667          |\n",
    "| (1,3)   |   0.730317          |\n",
    "| (2,3)   |   0.677534          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is n-gram size: (1, 1)\n",
      "Best parameter settings: {'C': 0.1}\n",
      "Validation accuracy: 0.753913\n",
      "This is n-gram size: (2, 2)\n",
      "Best parameter settings: {'C': 1.0}\n",
      "Validation accuracy: 0.695502\n",
      "This is n-gram size: (3, 3)\n",
      "Best parameter settings: {'C': 0.1}\n",
      "Validation accuracy: 0.619104\n",
      "This is n-gram size: (1, 2)\n",
      "Best parameter settings: {'C': 1.0}\n",
      "Validation accuracy: 0.742667\n",
      "This is n-gram size: (1, 3)\n",
      "Best parameter settings: {'C': 1.0}\n",
      "Validation accuracy: 0.730317\n",
      "This is n-gram size: (2, 3)\n",
      "Best parameter settings: {'C': 1.0}\n",
      "Validation accuracy: 0.677534\n"
     ]
    }
   ],
   "source": [
    "# code for 1.1 here\n",
    "ngram_sizes = [(1,1), (2,2), (3,3), (1,2), (1,3), (2,3)]\n",
    "for i in ngram_sizes:\n",
    "    X_train = vect.fit_transform(features(d, ngram_range=i) for d in text_train)\n",
    "    params = [{'C': [0.01, 0.1, 1.0]}]\n",
    "\n",
    "    # this performs 3-fold cross-validation with the above classifier and parameter options\n",
    "\n",
    "    gs_classifier = GridSearchCV(base_classifier, params, cv=3)\n",
    "    gs_classifier.fit(X_train, Y_train)\n",
    "\n",
    "    #print(gs_classifier.get_params())\n",
    "    print(\"This is n-gram size:\", i)\n",
    "    print(\"Best parameter settings:\", gs_classifier.best_params_)\n",
    "    print(\"Validation accuracy: %0.6f\" % gs_classifier.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 1.2: Describe what you observe with different length n-grams. When using only one type of n-gram (1, 2, or 3), how does the length affect accuracy? How does using only one size of n-gram (1, 2, or 3) compare to using a range of different sizes (1-2, 1-3, or 2-3)?\n",
    "\n",
    "[Although this is not the case for n-gram (1,1), the general pattern is that when you use a range of n-gram sizes, you get a better validation accuracy. Additionally, Wwen using only one type of n-gram (1,1) vs (2,2), vs (3,3), the accuracy decreases as the length increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "Selecting a subset of features can improve classifier efficiency and potentially guard against overfitting. However, it can also hurt performance if too many features are removed. We will now experiment with different levels of feature selection.\n",
    "\n",
    "We will use the [`SelectPercentile`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html) class, which can be used to select features that are within a specified percentile according to a scoring function that ranks the quality of the features. The code below instantiates a `SelectPercentile` object using the [`chi2`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html) function, which performs a chi-squared test for measuring the significance of features. The `percentile` argument specifies the percentile of features that are selected after ranking by their chi-squared statistic. If `percentile=1`, only the top 1% of features will be selected. If `percentile=100`, all features will be selected.\n",
    "\n",
    "Once you've created a `SelectPercentile` object, its `fit` function can be called to calculate the significance of the features, and its `transform` function will modify the feature vectors to choose only the selected features. The `fit_transform` function performs both of these steps, which is what you see below.\n",
    "\n",
    "Experiment with different feature selection percentiles to see how the accuracy is affected by different settings.\n",
    "\n",
    "#### Deliverable 1.3: Calculate the cross-validation accuracy at different values of `percentile`, when the percentile is each of $[1, 2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]$. Create a plot where the percentile is on the x-axis and the accuracy is on the y-axis. Do this for three different settings with the base classifer defined above, using n-gram ranges of (1,1), (2,2), and (1,3). You can either create three different figures for these three n-gram ranges, or create one figure with three lines (clearly labeled).\n",
    "\n",
    "[I created one plot with all three lines labeled.]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "\n",
    "# example: feature selection at the 60th percentile.\n",
    "# Note the renaming of the feature vectors to X_train_selected\n",
    "\n",
    "selection = SelectPercentile(percentile=60, score_func=chi2)\n",
    "X_train_selected = selection.fit_transform(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7370286953620288, 0.7449305365972032, 0.7629030545697212, 0.7673961840628508, 0.7651477234810568, 0.764014014014014, 0.7595284678618013, 0.75503913003913, 0.7516683350016683, 0.752802044468711, 0.7516759183425851, 0.7527982527982529, 0.753913003913004]\n",
      "[0.7617655534322202, 0.7617617617617617, 0.7471714138380805, 0.7404336154336154, 0.7527906694573362, 0.7179869263202597, 0.7067408317408317, 0.7022514939181606, 0.7033738283738283, 0.7067408317408317, 0.7089855006521674, 0.7146009646009647, 0.6955023205023205]\n",
      "[0.7730154396821064, 0.7819979069979069, 0.7775085691752358, 0.7707821457821457, 0.7628992628992629, 0.7460414960414962, 0.739303697637031, 0.7314435647768981, 0.7303136469803135, 0.7426744926744927, 0.7437930354597021, 0.7449229532562865, 0.730317438650772]\n"
     ]
    }
   ],
   "source": [
    "# code for 1.3 here\n",
    "\n",
    "percentile_values = [1,2,5,10,20,30,40,50,60,70,80,90,100]\n",
    "accuracy_vals_one = []\n",
    "for i in percentile_values:\n",
    "    X_train = vect.fit_transform(features(d, ngram_range=(1,1)) for d in text_train)\n",
    "    gs_classifier = GridSearchCV(base_classifier, params, cv=3)\n",
    "    \n",
    "    selection = SelectPercentile(percentile=i, score_func=chi2)\n",
    "    X_train_selected = selection.fit_transform(X_train, Y_train)\n",
    "    params = [{'C': [0.01, 0.1, 1.0]}]\n",
    "\n",
    "    gs_classifier = GridSearchCV(base_classifier, params, cv=3)\n",
    "    gs_classifier.fit(X_train_selected, Y_train)\n",
    "    accuracy_vals_one.append(gs_classifier.best_score_)\n",
    "print(accuracy_vals_one)\n",
    " \n",
    "accuracy_vals_two = []\n",
    "for i in percentile_values:\n",
    "    X_train = vect.fit_transform(features(d, ngram_range=(2,2)) for d in text_train)\n",
    "    gs_classifier = GridSearchCV(base_classifier, params, cv=3)\n",
    "    \n",
    "    selection = SelectPercentile(percentile=i, score_func=chi2)\n",
    "    X_train_selected = selection.fit_transform(X_train, Y_train)\n",
    "    params = [{'C': [0.01, 0.1, 1.0]}]\n",
    "\n",
    "    gs_classifier = GridSearchCV(base_classifier, params, cv=3)\n",
    "    gs_classifier.fit(X_train_selected, Y_train)\n",
    "    accuracy_vals_two.append(gs_classifier.best_score_)\n",
    "print(accuracy_vals_two)\n",
    " \n",
    "accuracy_vals_three = []\n",
    "for i in percentile_values:\n",
    "    X_train = vect.fit_transform(features(d, ngram_range=(1,3)) for d in text_train)\n",
    "    gs_classifier = GridSearchCV(base_classifier, params, cv=3)\n",
    "    \n",
    "    selection = SelectPercentile(percentile=i, score_func=chi2)\n",
    "    X_train_selected = selection.fit_transform(X_train, Y_train)\n",
    "    params = [{'C': [0.01, 0.1, 1.0]}]\n",
    "\n",
    "    gs_classifier = GridSearchCV(base_classifier, params, cv=3)\n",
    "    gs_classifier.fit(X_train_selected, Y_train)\n",
    "    accuracy_vals_three.append(gs_classifier.best_score_)\n",
    "print(accuracy_vals_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15eae1e80>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(percentile_values, accuracy_vals_one, label=\"(1,1)\", linewidth=3)\n",
    "plt.plot(percentile_values, accuracy_vals_two, label=\"(2,2)\", linewidth=3)\n",
    "plt.plot(percentile_values, accuracy_vals_three, label=\"(1,3)\", linewidth=3)\n",
    "plt.xlabel(\"Percentile\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 1.4: Describe what you observe in the 1.3 plots. Comment on any general patterns that you see across all of the plots, and explain why you think this behavior happens. Additionally, comment on any differences in the patterns between the three different classifiers. If there are any differences, what do you think explains the differences?\n",
    "\n",
    "[Generally, the n-gram lengths perform worse with increasing precentile of features. This is likely because the quality of the features included isnt as good. Thus, with only the highest quality features included, they generally perform better. This pattern looks a little different with (1,1) ngram. In this case the most selective percentile doesnt perform as well. This is likely because you are only working with words of length one. Thus, by only using a select number of features, this may be too limited information to perfrom optimally.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Feature Engineering \n",
    "\n",
    "### Problem 2 of the Coding Part is significantly more demanding this time. However, it is only worth 2 points out of the total 26 points. You might consider the return of the time and effort you need to put in when you work on the coding part.\n",
    "\n",
    "### Choosing final hyperparameters\n",
    "\n",
    "Above, you experimented with various ranges of n-grams and feature selection percentiles. For the remainder of this assignment, you should stick with one setting of n-gram range and percentile.\n",
    "\n",
    "In the code below, the variables `ngr` and `per` define the n-gram range and percentile that you will use in the remaining experience. Currently, `ngr` is set to $(1,3)$ and `per` is set to $100$, but you should modify these values as needed and set them to whatever values gave you the best validation accuracy in your experiments in Problem 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngr = (1,3)\n",
    "per = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are no longer tuning the hyperparameters, now is a reasonable time to also look at the test data. The code below calculates both the cross-validation as well as the accuracy on the test data using the best classifier from cross-validation, using the randomly chosen n-gram and percentile settings. \n",
    "\n",
    "You don't need to do anything in this section except understand and run the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.797753\n",
      "Test accuracy: 0.718182\n"
     ]
    }
   ],
   "source": [
    "X_train_final = vect.fit_transform(features(d, ngram_range=ngr) for d in text_train)\n",
    "X_test_final = vect.transform(features(d, ngram_range=ngr) for d in text_test)\n",
    "\n",
    "selection = SelectPercentile(percentile=per, score_func=chi2)\n",
    "X_train_final = selection.fit_transform(X_train_final, Y_train)\n",
    "X_test_final = selection.transform(X_test_final)\n",
    "\n",
    "gs_classifier = GridSearchCV(base_classifier, params, cv=5)\n",
    "gs_classifier.fit(X_train_final, Y_train)\n",
    "\n",
    "print(\"Validation accuracy: %0.6f\" % gs_classifier.best_score_)\n",
    "print(\"Test accuracy: %0.6f\" % accuracy_score(Y_test, gs_classifier.predict(X_test_final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new features\n",
    "\n",
    "How do you add new features? You will need to create a new feature extraction function. Start by copying the definition of the `features` function at the start of this notebook and renaming it. Keep everything from the original function, but write additional code that appends your new features to the `features_in_text` array. You can create any additional helper functions as needed.\n",
    "\n",
    "The description of each feature type is below. Be sure to read the instructions carefully.\n",
    "\n",
    "- **Skip-grams:** A type of feature that is related to an n-gram is a _skip-gram_. Skip-grams can be defined in different ways, but the definition you will use here is a sequence of word tokens where only the first and last word are specified, while any word token in between is replaced with a general placeholder symbol (usually an asterisk, $*$). For example, the string \"the water is cold\" contains two length-3 skip-grams (\"`the * is`\" and \"`water * cold`\") and one length-4 skip-gram (\"`the * * cold`\"). The purpose of skip-grams is to capture longer sequences while being general enough to match more instances than with longer n-grams. To implement a skip-gram of length $k$, you can simply extract $k$-grams (i.e., n-grams of length $k$) and replace the inner tokens with asterisks. Like with the n-gram features, the values of the skip-gram features should be their counts. For this assignment, you should extract skip-grams of both length 3 and length 4.\n",
    "- **Word pairs:** It may be helpful to encode combinations of words that appear in a document, regardless of whether they appear in a particular sequence. One type of feature is to indicate if two words are both present in a text (like doing an *AND* operation on the presense of the two unigrams). For example, the string \"the water is cold\" contains 6 distinct word pairs (\"`(the,water)`\", \"`(the,is)`\", \"`(the,cold)`\", \"`(water,is)`\", \"`(water,cold)`\", \"`(is,cold)`\"). For full credit, your code should not include pairs that are permutations of each other $-$ for example, include `(water,cold)` or `(cold,water)` but not both. An easy way to do this is to sort the words in alphabetical order within pairs. For this feature, simply use the value $1$ if the pair is present in a text and $0$ otherwise (that is, binary values rather than using full counts).\n",
    "- **Sentiment dictionary:** One might also take advantage of external resources others have created for sentiment analysis. For this type of feature, we will use a sentiment *lexicon* created by researcher [Bing Liu](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html), which is a list of words that have a tendency to show positive sentiment and a list of words with negative sentiment. The lexicon contains thousands of words; the words are already loaded for you in the code cell below. For this feature, you should extract n-grams (using whatever n-gram range was randomly selected above) where any word that appears in the positive dictionary is replaced with the capitalized string \"`POS`\" and any word in the negative dictionary is replaced with the string \"`NEG`\". For full credit, you should extract all original n-grams (before doing dictionary replacement) as well as n-grams with the replaced sentiment strings, but without double-counting the original n-grams. For example, the word \"cold\" is in the negative dictionary, so the string \"the water is cold\" should have five unigrams all with value $1$ (\"`the`\", \"`water`\", \"`is`\", \"`cold`\", \"`NEG`\"), and four bigrams with value with $1$ (\"`the water`\", \"`water is`\", \"`is cold`\", \"`is NEG`\").\n",
    "\n",
    "After writing your new function, you should test the function on a few example strings to see if it is extracting features in the way you expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 2.1: Say which feature(s) you were able to implemented.  If you were unable to fully implement them all, describe what you attempted to do, and any challenges you ran into. \n",
    "\n",
    "[I was able to implement all 3: skip-grams, word pairs, and sentiment dictionary. No challenges encountered.]\n",
    "\n",
    "#### Deliverable 2.2: Calculate the cross-validation accuracy and test accuracy using your new feature set. Compare the new accuracies with the accuracies in the code cell above, before you changed the features. Your new features may help, hurt, or make no change to the accuracy. In any case, give a possible explanation for why it affected (or didn't affect) the accuracy.\n",
    "\n",
    "[All my code is below. Using skip grams improved the accuracy with ngram (1,3), likely because you have an increased number of occurances now that have the same semantic meaning (pos, neg, neut). You have an increased number of occurances because you need fewer words to match because the words in the middle are replaced with an \"*\". However, the sentiment of the word liekly stays the same. For example if you were to have \"The room was cold\" and \"The shower was cold\", both of these are negative. With the previously used feature these would be classified as separate phrases but now with the skip grams, they would be classified as the same phrase. It seems that using word pairs slightly worsens performance. Using the sentiment dictionary slightly increases accuracy. This makes sense because you are using a sentiment bank to help find words.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you are using the third feature type (sentiment dictionary),\n",
    "## run this block of code.\n",
    "\n",
    "# (original source: http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar )\n",
    "\n",
    "sentiment_df = pd.read_csv('sentiment-words.csv', header=None, encoding='ISO-8859-1')\n",
    "\n",
    "# The two variables, positive_words and negative_words, are sets that contain the positive/negative words\n",
    "\n",
    "positive_words = sentiment_df.loc[sentiment_df[0] == 'positive']\n",
    "positive_words = set(positive_words.iloc[0:, 1].values)\n",
    "\n",
    "negative_words = sentiment_df.loc[sentiment_df[0] == 'negative']\n",
    "negative_words = set(negative_words.iloc[0:, 1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'comely', 'harmoniously', 'manageable', 'rejoicingly', 'exalted', 'cheery', 'fascinating', 'fervently', 'wholeheartedly', 'sweetly', 'guarantee', 'endorsing', 'electrify', 'pleasing', 'master', 'improve', 'effusively', 'heaven', 'tremendously', 'winnable', 'illuminate', 'admiringly', 'accommodative', 'intriguingly', 'stabilize', 'exuberantly', 'energy-saving', 'cleared', 'quieter', 'optimism', 'relaxed', 'clever', 'intriguing', 'mercy', 'bullish', 'hopeful', 'celebrate', 'luck', 'piety', 'realizable', 'nicest', 'affability', 'lucidly', 'efficient', 'enthrall', 'spacious', 'well-intentioned', 'stainless', 'amazed', 'loving', 'lead', 'hail', 'valor', 'dote', 'luckiness', 'successful', 'jollify', 'hooray', 'idolized', 'rapport', 'easygoing', 'keen', 'stirringly', 'supremely', 'reclaim', 'excellency', 'humble', 'revive', 'marveled', 'wonder', 'humour', 'gleefully', 'satisfies', 'flawless', 'adroit', 'prudence', 'navigable', 'foresight', 'well-connected', 'breeze', 'heavenly', 'excels', 'risk-free', 'glimmer', 'effusiveness', 'sturdy', 'maturity', 'rejuvenate', 'spotless', 'regal', 'amazement', 'enthusiast', 'aspirations', 'facilitate', 'productively', 'progressive', 'superb', 'fertile', 'compliant', 'breathlessness', 'luckiest', 'rightful', 'lawfully', 'principled', 'glimmering', 'accomplish', 'fast-growing', 'vibrant', 'congratulatory', 'tidy', 'insightful', 'accessable', 'exonerate', 'fashionable', 'humourous', 'instantly', 'overtake', 'acumen', 'flourishing', 'industrious', 'well-being', 'rock-star', 'suffices', 'geeky', 'dignity', 'ardent', 'individualized', 'endear', 'exultation', 'steadfastness', 'edify', 'gladness', 'felicitous', 'majesty', 'ebullience', 'paramount', 'remarkable', 'favorite', 'civilize', 'spellbinding', 'clear', 'tough', 'agreeableness', 'lifesaver', 'prudent', 'advanced', 'heartfelt', 'ideally', 'alluringly', 'patriotic', 'satisfying', 'jaw-droping', 'hard-working', 'saint', 'glamorous', 'steadfast', 'win', 'effectual', 'hallmark', 'painlessly', 'breathtaking', 'endorsement', 'resound', 'timely', 'traction', 'charisma', 'advocated', 'complimentary', 'smiling', 'awesomely', 'dependable', 'safe', 'awarded', 'enthusiastic', 'flutter', 'masterpieces', 'useful', 'adaptive', 'accomplishments', 'avid', 'suavely', 'bliss', 'trustingly', 'excelled', 'noteworthy', 'gush', 'reliably', 'felicitate', 'triumphal', 'purposeful', 'beckons', 'evocative', 'capability', 'fun', 'high-quality', 'miraculously', 'convienient', 'leverage', 'honoring', 'devout', 'divine', 'virtue', 'precious', 'low-priced', 'gallantly', 'acclaimed', 'vivacious', 'inventive', 'ambitiously', 'celebration', 'embolden', 'breathtakingly', 'blessing', 'self-respect', 'smoothly', 'fair', 'courteous', 'skilled', 'gusto', 'ftw', 'luster', 'beautiful', 'vigilance', 'fervent', 'unquestionably', 'well-wishers', 'incredible', 'beautifully', 'pampers', 'darling', 'venerate', 'appreciates', 'resilient', 'frolic', 'delicious', 'sagacity', 'accomodative', 'brilliantly', 'shine', 'positive', 'overtakes', 'sensational', 'cuteness', 'geekier', 'outsmart', 'restructured', 'world-famous', 'god-send', 'inviolable', 'miracle', 'respite', 'helping', 'healthy', 'lovely', 'attractively', 'elan', 'endorses', 'harmonious', 'empowerment', 'upliftment', 'sensibly', 'authoritative', 'exhilarating', 'bravery', 'spellbindingly', 'rightly', 'lucrative', 'stylized', 'pamper', 'amazes', 'rapid', 'affection', 'captivating', 'soft', 'hale', 'advantageous', 'excites', 'heal', 'sufficiently', 'undamaged', 'cohere', 'entranced', 'faith', 'liberty', 'mesmerizing', 'recommendations', 'reformed', 'astounded', 'leading', 'idol', 'futurestic', 'adoring', 'properly', 'thoughtful', 'retractable', 'exult', 'surreal', 'confidence', 'passionate', 'smarter', 'lucid', 'privilege', 'poeticize', 'prodigiously', 'lively', 'trustworthiness', 'outdone', 'goodness', 'brand-new', 'rich', 'credible', 'motivated', 'subsidized', 'hospitable', 'trivially', 'stylish', 'titillate', 'worth', 'prestigious', 'profound', 'defeats', 'staunch', 'attraction', 'entrancing', 'hero', 'adventuresome', 'easiest', 'greatest', 'invulnerable', 'well', 'benevolence', 'masters', 'glowingly', 'exalting', 'luxuriously', 'encouragingly', 'impeccable', 'truthfully', 'counter-attack', 'celebrated', 'hardier', 'easy-to-use', 'influential', 'convenience', 'cleanliness', 'invigorating', 'righteously', 'rapt', 'momentous', 'unequivocally', 'yay', 'refund', 'relent', 'heroic', 'well-behaved', 'harmless', 'simplifies', 'fresh', 'liked', 'supported', 'savings', 'well-positioned', 'righteous', 'favor', 'rightness', 'promises', 'intuitive', 'unbiased', 'gratefully', 'brighter', 'whooa', 'champion', 'propitiously', 'tranquil', 'zenith', 'affectionate', 'examplary', 'simpler', 'proper', 'buoyant', 'firmer', 'applaud', 'coherence', 'excitement', 'dependably', 'preeminent', 'remarkably', 'conciliatory', 'sporty', 'crisp', 'beckon', 'conveniently', 'dominated', 'eased', 'gratitude', 'altruistic', 'mighty', 'pamperedness', 'simplified', 'abounds', 'gainful', 'upliftingly', 'decent', 'congenial', 'groundbreaking', 'wondrous', 'bargain', 'romantic', 'ample', 'elegantly', 'merciful', 'fanfare', 'roomy', 'equitable', 'consummate', 'victory', 'sophisticated', 'beauty', 'admirable', 'appreciated', 'conscientious', 'adulation', 'loveliness', 'terrifically', 'congratulation', 'euphoric', 'picturesque', 'chic', 'illumine', 'adoringly', 'chivalry', 'laudable', 'soothingly', 'titillatingly', 'brainy', 'sagely', 'rectifying', 'tickle', 'well-established', 'rejoice', 'benevolent', 'polite', 'eager', 'dead-cheap', 'affirm', 'elate', 'peerless', 'splendid', 'readily', 'affably', 'attractive', 'fascination', 'unbeatable', 'preferring', 'uncomplicated', 'fiery', 'sumptuousness', 'supple', 'compassionate', 'excellant', 'keenly', 'dignify', 'reasonable', 'splendor', 'neatly', 'exhilarate', 'infallible', 'eyecatch', 'humane', 'luxuriant', 'supreme', 'outperforming', 'enjoys', 'brisk', 'extoll', 'awed', 'soundness', 'miracles', 'remission', 'effectively', 'improvements', 'amusingly', 'mercifully', 'winner', 'precisely', 'aspiration', 'blockbuster', 'regard', 'honored', 'ideal', 'willingly', 'bonuses', 'modest', 'authentic', 'smooth', 'charmingly', 'unity', 'maturely', 'protection', 'ergonomical', 'valiantly', 'flexible', 'renowned', 'cure-all', 'exhilaration', 'jovial', 'wowing', 'profuse', 'whoa', 'witty', 'recommendation', 'veritable', 'morality', 'assurances', 'avidly', 'reasoned', 'standout', 'eminent', 'nicer', 'enchant', 'astounding', 'wonders', 'distinctive', 'easy', 'merry', 'catchy', 'heartening', 'loyal', 'beauteous', 'astonishing', 'ease', 'satisfactorily', 'pleasurably', 'cost-saving', 'revolutionize', 'resourcefulness', 'impressiveness', 'popular', 'unwavering', 'tempt', 'dazzled', 'undisputable', 'steadfastly', 'calming', 'praising', 'fearless', 'amity', 'sparkling', 'sweetheart', 'inestimably', 'zeal', 'self-sufficient', 'amply', 'amazing', 'sweeten', 'competitive', 'enraptured', 'inspire', 'redeem', 'levity', 'unfazed', 'refunded', 'engaging', 'angelic', 'fortune', 'tantalize', 'handsome', 'topnotch', 'earnestness', 'fulfillment', 'modesty', 'peacefully', 'first-rate', 'prosperity', 'nifty', 'cost-effective', 'readable', 'agility', 'fond', 'heroically', 'strong', 'cheer', 'subsidizing', 'matchless', 'gooood', 'remunerate', 'upbeat', 'pepping', 'merrily', 'grandeur', 'smoothes', 'lavish', 'god-given', 'raptureously', 'famous', 'precise', 'reconcile', 'recommended', 'magical', 'sexy', 'agreeably', 'beautify', 'like', 'paradise', 'promise', 'admiring', 'speedily', 'civility', 'excelent', 'benefit', 'elatedly', 'nurturing', 'benefits', 'enthuse', 'appreciative', 'courtly', 'fancy', 'courageous', 'exellent', 'refined', 'grin', 'educated', 'exalt', 'brighten', 'cashback', 'unfettered', 'fastest-growing', 'revolutionized', 'captivate', 'faster', 'stylishly', 'positively', 'intimate', 'calm', 'stimulates', 'energy-efficient', 'upgradeable', 'noiseless', 'perfect', 'contrasty', 'handy', 'praiseworthy', 'succes', 'goodly', 'joyfully', 'fast-paced', 'kid-friendly', 'responsive', 'eagerly', 'dashing', 'cleanest', 'enticingly', 'mind-blowing', 'priceless', 'awe', 'gratification', 'renown', 'approval', 'tender', 'multi-purpose', 'formidable', 'gratifying', 'rewardingly', 'won', 'wholesome', 'zest', 'conciliate', 'achievible', 'heroize', 'heartwarming', 'fairly', 'simplifying', 'spellbind', 'proficient', 'obtainable', 'meticulous', 'accomplished', 'excellence', 'solicitous', 'homage', 'dazzling', 'capable', 'exquisitely', 'superior', 'large-capacity', 'balanced', 'winners', 'happier', 'ambitious', 'toll-free', 'invincibility', 'personages', 'rockstar', 'generous', 'gorgeously', 'afford', 'agreeable', 'appeal', 'substantive', 'envious', 'amicable', 'favored', 'relish', 'enviously', 'credence', 'nobly', 'amenity', 'wows', 'quicker', 'destiny', 'adorable', 'succeed', 'rectification', 'clearer', 'beloved', 'humor', 'cleverly', 'glitter', 'thriving', 'inpressed', 'replaceable', 'fascinate', 'resounding', 'astonish', 'personalized', 'youthful', 'complementary', 'knowledgeable', 'stimulate', 'impressive', 'idyllic', 'swankier', 'luxurious', 'non-violence', 'easing', 'effectiveness', 'monumentally', 'adulatory', 'sweetness', 'aspire', 'thinner', 'blithe', 'fortuitous', 'delicacy', 'productive', 'affinity', 'upgraded', 'ecenomical', 'ingeniously', 'gain', 'sharp', 'cushy', 'hallmarks', 'fastest', 'saver', 'imaginative', 'well-made', 'law-abiding', 'deginified', 'improved', 'handier', 'meaningful', 'reputation', 'unlimited', 'prodigy', 'meticulously', 'diligently', 'champ', 'lavishly', 'right', 'regally', 'abundance', 'agile', 'brainiest', 'sturdier', 'engrossing', 'enjoyably', 'supporting', 'glorious', 'defeating', 'deserving', 'suffice', 'whoooa', 'cherished', 'endorsed', 'affluent', 'distinction', 'sleek', 'slick', 'slammin', 'laud', 'intricate', 'swift', 'commodious', 'thrive', 'cheapest', 'mesmerizes', 'pure', 'outperform', 'radiance', 'dauntless', 'profoundly', 'transparent', 'playful', 'abundant', 'easiness', 'low-price', 'diligence', 'wisely', 'outshone', 'pluses', 'resplendent', 'altruistically', 'roomier', 'infallibly', 'adore', 'tolerable', 'cheerful', 'trump', 'adroitly', 'mesmerized', 'commendably', 'suitable', 'satisfied', 'preferes', 'stupendous', 'reaffirm', 'serenity', 'proficiently', 'free', 'righten', 'wieldy', 'fervor', 'elevate', 'excitedness', 'a+', 'overtaken', 'prosper', 'spiritual', 'sufficient', 'danken', 'lovable', 'verifiable', 'soothe', 'enticing', 'majestic', 'desiring', 'honesty', 'visionary', 'permissible', 'pinnacle', 'grace', 'enthusiasm', 'deservedly', 'obsession', 'acclaim', 'succeeded', 'all-around', 'convincing', 'luxuriate', 'admirably', 'recommend', 'revelation', 'beneficent', 'patiently', 'ready', 'delight', 'cooperatively', 'talents', 'enlighten', 'magnificent', 'neat', 'exaltingly', 'sane', 'worth-while', 'gainfully', 'tenacity', 'successes', 'guidance', 'flexibility', 'fragrant', 'revolutionizes', 'enhanced', 'magic', 'cherub', 'improving', 'everlasting', 'honor', 'redemption', 'kindly', 'revere', 'wisdom', 'enjoying', 'reconciliation', 'fine-looking', 'sincerity', 'congratulations', 'propitious', 'supporter', 'peace', 'revival', 'ardor', 'chaste', 'inviolate', 'bolster', 'unabashed', 'proves', 'angel', 'colorful', 'extraordinarily', 'warmly', 'wonderous', 'immaculate', 'preferable', 'splendidly', 'liking', 'statuesque', 'comforting', 'strikingly', 'peaceable', 'virtuous', 'felicity', 'marvels', 'better-known', 'fascinatingly', 'idolize', 'polished', 'appropriate', 'swanky', 'pleasure', 'brightest', 'stable', 'ilu', 'continuity', 'miraculousness', 'humorously', 'prefers', 'reasonably', 'ecstasies', 'joyful', 'woo', 'magnificently', 'favorable', 'swiftness', 'reward', 'articulate', 'redeeming', 'restful', 'rapture', 'dexterously', 'renaissance', 'compliment', 'ebulliently', 'eulogize', 'glad', 'stunningly', 'gallant', 'robust', 'top', 'unparalleled', 'exhilaratingly', 'gaily', 'wonderously', 'meritorious', 'invaluable', 'endorse', 'recovery', 'bless', 'unaffected', 'rejuvenating', 'stunned', 'enjoyment', 'admire', 'optimal', 'shiny', 'smartly', 'flattering', 'thrills', 'wonderful', 'outstrip', 'lush', 'flatter', 'savvy', 'entice', 'fidelity', 'merit', 'sumptuous', 'proactive', 'encouragement', 'believable', 'interests', 'impartial', 'outwit', 'divinely', 'skillfully', 'inspiring', 'warm', 'lucky', 'surmount', 'impress', 'salutary', 'mature', 'unreal', 'halcyon', 'lean', 'upgradable', 'selective', 'understandable', 'hallowed', 'happiness', 'glee', 'thrillingly', 'top-notch', 'backbone', 'willingness', 'dreamland', 'pleasingly', 'panoramic', 'serene', 'enhancement', 'jaw-dropping', 'respectfully', 'eagerness', 'inspirational', 'lawful', 'treasure', 'passionately', 'gifted', 'clears', 'noble', 'reforms', 'bloom', 'accessible', 'rapturous', 'long-lasting', 'accolades', 'impressed', 'cozy', 'enhance', 'sweeping', 'attune', 'bright', 'obsessions', 'sweet', 'stronger', 'glow', 'reassurance', 'evaluative', 'well-backlit', 'purify', 'striving', 'encouraging', 'humility', 'best-known', 'prominence', 'premier', 'comfortable', 'illustrious', 'enhances', 'lustrous', 'delectable', 'luxury', 'rectify', 'supurb', 'undaunted', 'unselfish', 'suave', 'sociable', 'affluence', 'enthusiastically', 'enviably', 'appreciate', 'trusted', 'optimistic', 'thrilling', 'courage', 'survival', 'pre-eminent', 'proven', 'first-in-class', 'available', 'openly', 'radiant', 'incredibly', 'palatial', 'charismatic', 'graciousness', 'vibrantly', 'savior', 'richly', 'decisiveness', 'perfection', 'amiabily', 'saintliness', 'innocuous', 'lighter', 'considerate', 'freedom', 'well-mannered', 'evenly', 'energize', 'covenant', 'satisified', 'thrift', 'affordably', 'secure', 'genius', 'eye-catch', 'shimmering', 'cool', 'posh', 'skill', 'temptingly', 'nourishing', 'marvelously', 'jubilantly', 'strongest', 'quaint', 'illuminating', 'promised', 'steady', 'fine', 'overture', 'thrifty', 'resolute', 'fast', 'honorable', 'apotheosis', 'coherent', 'superbly', 'complements', 'dumbfounded', 'delighted', 'powerfully', 'providence', 'versatile', 'thumbs-up', 'seamless', 'glorify', 'clear-cut', 'fantastic', 'restored', 'portable', 'beckoning', 'pepped', 'talented', 'good', 'enough', 'well-rounded', 'brilliant', 'enrapture', 'freed', 'effortlessly', 'marvelousness', 'miraculous', 'reassure', 'revitalize', 'joy', 'reverence', 'reliable', 'erudite', 'stupendously', 'charming', 'eventful', 'well-known', 'refresh', 'soulful', 'tenacious', 'goood', 'solid', 'breakthrough', 'relief', 'entertain', 'enchanting', 'award', 'laudably', 'desirable', 'decisive', 'zippy', 'tempting', 'diplomatic', 'perfectly', 'loves', 'poised', 'clearly', 'instrumental', 'commendable', 'wellbeing', 'benifits', 'advocate', 'integral', 'stability', 'amicability', 'enliven', 'sincere', 'celebratory', 'irreplaceable', 'cashbacks', 'gaiety', 'masterful', 'snazzy', 'respectable', 'impeccably', 'foremost', 'unmatched', 'gorgeous', 'earnestly', 'silent', 'truthfulness', 'proud', 'warmer', 'expertly', 'responsibly', 'accurate', 'glisten', 'likable', 'gem', 'usable', 'gains', 'happily', 'pleasant', 'accurately', 'sustainable', 'receptive', 'effusive', 'nourishment', 'triumphantly', 'immaculately', 'gold', 'eminence', 'glitz', 'sublime', 'adequate', 'comfy', 'adaptable', 'blissful', 'deft', 'exceeds', 'entertaining', 'impassioned', 'earnest', 'subsidizes', 'exceptionally', 'best-selling', 'exuberant', 'marvelled', 'renewed', 'fantastically', 'beckoned', 'integrated', 'love', 'genial', 'peaceful', 'diversified', 'rejuvenated', 'well-balanced', 'benefactor', 'ingenuous', 'acclamation', 'smartest', 'enchanted', 'steadiness', 'beneficial', 'kudos', 'patience', 'thrilled', 'extol', 'warmth', 'exciting', 'issue-free', 'futuristic', 'audibly', 'exceeding', 'romantically', 'adjustable', 'boost', 'impresses', 'cajole', 'irresistibly', 'recomend', 'likes', 'irresistible', 'hands-down', 'defeat', 'victorious', 'significant', 'trophy', 'concise', 'worthwhile', 'commitment', 'carefree', 'generosity', 'unabashedly', 'effortless', 'vouch', 'unencumbered', 'calmness', 'clarity', 'tenaciously', 'privileged', 'well-educated', 'ecstasy', 'prosperous', 'glowing', 'sensitive', 'cure', 'ecstatic', 'user-replaceable', 'exemplary', 'plusses', 'irreproachable', 'awesome', 'solace', 'intelligent', 'punctual', 'magnanimous', 'blissfully', 'fabulously', 'attentive', 'fairness', 'enthralled', 'idealize', 'satisfy', 'proving', 'reverent', 'feat', 'tops', 'worthiness', 'achievement', 'pain-free', 'peacekeepers', 'convient', 'praise', 'judicious', 'inestimable', 'exultant', 'fabulous', 'astonishment', 'extraordinary', 'graceful', 'overtaking', 'approve', 'outperformed', 'gleeful', 'intelligible', 'jubilant', 'stunning', 'resourceful', 'cornerstone', 'brilliances', 'fortuitously', 'pep', 'opulent', 'enticed', 'enjoy', 'safely', 'sustainability', 'trouble-free', 'versatility', 'fancinating', 'prodigious', 'pleasantly', 'well-bred', 'affectation', 'auspicious', 'orderly', 'unquestionable', 'reputable', 'dexterous', 'superiority', 'complemented', 'prefer', 'impressively', 'marvelous', 'brilliance', 'convience', 'enchantingly', 'err-free', 'originality', 'dynamic', 'revel', 'valiant', 'delightful', 'indulgent', 'spectacularly', 'foolproof', 'toughest', 'problem-solver', 'delicate', 'gaining', 'heartily', 'outstanding', 'survivor', 'inspiration', 'eloquently', 'overjoyed', 'patient', 'overtook', 'playfully', 'danke', 'solidarity', 'elation', 'recover', 'light-hearted', 'fancier', 'doubtless', 'illuminati', 'truthful', 'indulgence', 'happy', 'perseverance', 'gained', 'peach', 'euphoria', 'rock-stars', 'inexpensive', 'finely', 'beneficiary', 'better', 'enjoyable', 'saintly', 'ebullient', 'achievable', 'outshine', 'enrichment', 'believeable', 'jubiliant', 'staunchly', 'gladly', 'enthral', 'astoundingly', 'impartially', 'stellarly', 'stimulating', 'cleaner', 'shimmeringly', 'beautifullly', 'snappy', 'talent', 'chivalrous', 'fervid', 'nicely', 'dominate', 'dazzle', 'lover', 'worthy', 'powerful', 'elegant', 'thank', 'sumptuously', 'promising', 'brave', 'succeeds', 'agilely', 'excitedly', 'twinkly', 'exceed', 'enrapt', 'excellent', 'pros', 'refreshed', 'enlightenment', 'crisper', 'grateful', 'supports', 'surpass', 'galore', 'improves', 'innovative', 'fashionably', 'amenable', 'romanticize', 'works', 'winning', 'enrich', 'appealing', 'mesmerize', 'feature-rich', 'exuberance', 'self-satisfaction', 'gratifies', 'effective', 'preferably', 'unrestricted', 'advantage', 'brotherly', 'respectful', 'triumph', 'endearing', 'rejoicing', 'audible', 'effusion', 'keenness', 'uplift', 'faithfully', 'examplar', 'wise', 'encourage', 'aver', 'straightforward', 'nourish', 'hot', 'thoughtfulness', 'reaffirmation', 'elite', 'amuse', 'honest', 'fav', 'godsend', 'immense', 'loved', 'finer', 'smiles', 'prudently', 'spectacular', 'bonus', 'leads', 'exceedingly', 'assurance', 'delightfulness', 'protect', 'trustworthy', 'kindness', 'blameless', 'qualify', 'handily', 'pleased', 'cheaper', 'first-class', 'legendary', 'envy', 'refreshing', 'fluent', 'affordable', 'rosy', 'reachable', 'excellently', 'charm', 'gentlest', 'virtuously', 'elegance', 'enterprising', 'astonished', 'thumb-up', 'rapturously', 'harmony', 'grand', 'charitable', 'beneficially', 'flourish', 'richer', 'seasoned', 'gratified', 'gracefully', 'gentle', 'genuine', 'valuable', 'smitten', 'courageousness', 'energetic', 'politeness', 'stately', 'beutifully', 'boom', 'creative', 'exceptional', 'dignified', 'unassailable', 'gutsy', 'exaltedly', 'undisputed', 'humorous', 'speedy', 'raptureous', 'gladden', 'spellbound', 'supurbly', 'vivid', 'pride', 'achievements', 'flatteringly', 'pampered', 'sharpest', 'comfortably', 'gloriously', 'thrill', 'masterfully', 'fortunately', 'reverently', 'gratify', 'subsidize', 'bountiful', 'patriot', 'simplest', 'durable', 'pleases', 'prettily', 'memorable', 'graciously', 'cute', 'fortitude', 'exceled', 'freedoms', 'feisty', 'openness', 'contribution', 'ardently', 'classic', 'daring', 'phenomenally', 'deference', 'compassion', 'solicitously', 'plentiful', 'top-quality', 'daringly', 'positives', 'assuring', 'hearten', 'skillful', 'prominent', 'headway', 'trust', 'rightfully', 'efficiently', 'problem-free', 'compact', 'pamperedly', 'ethical', 'fave', 'soundly', 'invincible', 'eloquent', 'favorited', 'vouchsafe', 'compactly', 'empower', 'masterpiece', 'low-risk', 'fans', 'willing', 'wins', 'reform', 'tougher', 'merriness', 'helpful', 'striking', 'hardy', 'flawlessly', 'breakthroughs', 'guiltless', 'simplify', 'successfully', 'record-setting', 'neatest', 'congratulate', 'thankful', 'awesomeness', 'super', 'commend', 'glory', 'convincingly', 'led', 'enjoyed', 'spontaneous', 'rewarding', 'astound', 'trendy', 'progress', 'entrust', 'lovably', 'advocates', 'magnificence', 'peppy', 'phenomenal', 'scenic', 'sprightly', 'favour', 'healthful', 'friendly', 'excallent', 'instructive', 'confident', 'dummy-proof', 'salute', 'wow', 'rational', 'efficacious', 'contentment', 'low-cost', 'wowed', 'correct', 'promptly', 'triumphant', 'sensationally', 'indebted', 'unequivocal', 'impartiality', 'dominates', 'satisfactory', 'amazingly', 'dumbfounding', 'distinguished', 'jubilation', 'righteousness', 'economical', 'excited', 'qualified', 'trumpet', 'undisputably', 'securely', 'expansive', 'time-honored', 'hottest', 'steadiest', 'succeeding', 'uphold', 'helped', 'luminous', 'improvement', 'poise', 'festive', 'tenderly', 'richness', 'comprehensive', 'success', 'sharper', 'restructure', 'revolutionary', 'eases', 'trusty', 'work', 'amiable', 'imaculate', 'poetic', 'greatness', 'well-informed', 'adorer', 'prefered', 'supportive', 'decency', 'well-managed', 'protective', 'merriment', 'complement', 'justly', 'empathize', 'lyrical', 'staunchness', 'loyalty', 'exaltation', 'lionhearted', 'feasible', 'intelligence', 'razor-sharp', 'booming', 'self-sufficiency', 'dextrous', 'ingenuity', 'oasis', 'pretty', 'adulate', 'freshest', 'quiet', 'softer', 'upheld', 'sensible', 'variety', 'faultless', 'outperforms', 'advantageously', 'hotcake', 'well-regarded', 'bravo', 'famed', 'support', 'self-determination', 'marvellous', 'desirous', 'frugal', 'straighten', 'adored', 'jubilate', 'insightfully', 'counter-attacks', 'fame', 'accolade', 'dead-on', 'maneuverable', 'fruitful', 'assuredly', 'smart', 'ennoble', 'elated', 'fervidly', 'admiration', 'excel', 'painless', 'terrific', 'interesting', 'state-of-the-art', 'unconditional', 'respect', 'ingenuously', 'luckier', 'prestige', 'infallibility', 'smile', 'lower-priced', 'hotcakes', 'plush', 'delightfully', 'consistent', 'warmhearted', 'afordable', 'invigorate', 'consistently', 'bonny', 'prowess', 'smilingly', 'friendliness', 'spirited', 'streamlined', 'best-performing', 'unforgettable', 'tantalizing', 'vigilant', 'ecstatically', 'worked', 'faithfulness', 'godlike', 'affirmation', 'unrivaled', 'easier', 'euphorically', 'ingenious', 'fondly', 'nimble', 'magnanimously', 'well-received', 'boundless', 'stellar', 'gratifyingly', 'invaluablely', 'ovation', 'amusing', 'exultingly', 'poignant', 'holy', 'important', 'amiability', 'intrigue', 'excite', 'exemplar', 'outdo', 'cleanly', 'heros', 'sufficed', 'abound', 'mightily', 'pleasurable', 'fearlessly', 'empathy', 'golden', 'outstandingly', 'prolific', 'passion', 'enviousness', 'better-than-expected', 'cooperative', 'tantalizingly', 'dotingly', 'liberate', 'persevere', 'useable', 'non-violent', 'faithful', 'joyous', 'heroine', 'cohesive', 'diligent', 'exceeded', 'eye-catching', 'dawn', 'appreciable', 'smoothest', 'trusting', 'comfort', 'coolest', 'wonderfully', 'accomplishment', 'compatible', 'eyecatching', 'high-spirited', 'expeditiously', 'entertains', 'feasibly', 'appreciatively', 'capably', 'windfall', 'fortunate', 'rockstars', 'eloquence', 'best', 'nice', 'finest', 'supremacy', 'thoughtfully', 'realistic', 'joyously', 'exquisite', 'novelty', 'stimulative', 'pardon', 'jolly', 'liberation', 'glistening', 'titillating', 'dirt-cheap', 'mesmerizingly', 'sincerely', 'kindliness', 'sparkle', 'awestruck', 'intimacy', 'mastery', 'awsome', 'flashy', 'notably', 'detachable', 'awards', 'togetherness', 'sensations', 'prospros', 'ameliorate', 'sensation', 'admirer', 'generously', 'defeated', 'profusion', 'amaze', 'hilarious', 'gems', 'restructuring', 'tranquility', 'great', 'unbound', 'alluring', 'smoother', 'adventurous', 'clean', 'dedicated', 'autonomous', 'logical', 'refinement', 'refine', 'ultra-crisp', 'reforming', 'modern', 'amicably', 'prompt', 'fecilitous', 'wealthy', 'assure', 'tingle', 'courageously', 'promoter', 'advantages', 'marvel', 'remedy', 'revives', 'affable', 'innovation', 'workable', 'peps', 'fresher', 'gumption', 'user-friendly', 'viewable', 'upscale', 'classy', 'astonishingly', 'handsomely', 'blossom', 'prize', 'goodwill', 'affirmative', 'convenient', 'monumental', 'excitingly', 'gracious', 'cherish', 'enviable', 'uplifting', 'well-run', 'defender', 'harmonize', 'swank', 'astutely', 'fondness', 'correctly', 'swankiest', 'constructive', 'famously', 'welcome', 'hug'}\n"
     ]
    }
   ],
   "source": [
    "print(positive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip grams\n",
    "def features_skip(text, ngram_range=(1,3)):\n",
    "    text = text.lower()      # make the string lowercase\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)     # remove consecutive characters that are repeated more than twice\n",
    "    \n",
    "    features_in_text = []   # running list of all features in this instance (can be repeated)\n",
    "    \n",
    "    # treat alphanumeric characters as word tokens (removing anything else),\n",
    "    # and extract all n-grams of length n specified by ngram_range\n",
    "    \n",
    "    text_alphanum = re.sub('[^a-z0-9]', ' ', text)\n",
    "    for n in range(ngram_range[0], ngram_range[1]+1):\n",
    "        features_in_text += ngrams(text_alphanum.split(), n)\n",
    "    \n",
    "    # replace word ngrams with asterisks\n",
    "    for index, ngram in enumerate(features_in_text):\n",
    "        word_vec = ngram.split()\n",
    "        word_vec_len = len(word_vec)\n",
    "        if word_vec_len > 2:\n",
    "            asterisk_count = word_vec_len - 2\n",
    "            features_in_text[index] = \" \".join([word_vec[0]] + [\"*\"]*asterisk_count + [word_vec[-1]])\n",
    "    \n",
    "    # now treat punctuation as word tokens, and get their counts (only unigrams)\n",
    "    \n",
    "    text_punc = re.sub('[a-z0-9]', ' ', text)\n",
    "    features_in_text += ngrams(text_punc.split(), 1)\n",
    "    \n",
    "    # 'Counter' converts a list into a dictionary whose keys are the list elements \n",
    "    #  and the values are the number of times each element appeared in the list\n",
    "    return Counter(features_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'a': 2, 'sentence': 2, 'it': 2, 's': 2, 'a sentence': 2, 'it s': 2, '!!': 2, ',': 2, \"'\": 2, 'this': 1, 'is': 1, 'an': 1, 'example': 1, 'of': 1, 'to': 1, 'tokenize': 1, 'actually': 1, 'more': 1, 'than': 1, 'two': 1, 'sentences': 1, 'this is': 1, 'is an': 1, 'an example': 1, 'example of': 1, 'of a': 1, 'sentence to': 1, 'to tokenize': 1, 'tokenize actually': 1, 'actually it': 1, 's more': 1, 'more than': 1, 'than a': 1, 'sentence it': 1, 's two': 1, 'two sentences': 1, 'this * an': 1, 'is * example': 1, 'an * of': 1, 'example * a': 1, 'of * sentence': 1, 'a * to': 1, 'sentence * tokenize': 1, 'to * actually': 1, 'tokenize * it': 1, 'actually * s': 1, 'it * more': 1, 's * than': 1, 'more * a': 1, 'than * sentence': 1, 'a * it': 1, 'sentence * s': 1, 'it * two': 1, 's * sentences': 1})\n"
     ]
    }
   ],
   "source": [
    "text = \"This is an example of a sentence to tokenize!! Actually, it's more than a sentence, it's two sentences!!!\"\n",
    "\n",
    "print(features_skip(text, ngram_range=(1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.801124\n",
      "Test accuracy: 0.736364\n"
     ]
    }
   ],
   "source": [
    "# Skip gram\n",
    "X_train_final = vect.fit_transform(features_skip(d, ngram_range=ngr) for d in text_train)\n",
    "X_test_final = vect.transform(features_skip(d, ngram_range=ngr) for d in text_test)\n",
    "\n",
    "selection = SelectPercentile(percentile=per, score_func=chi2)\n",
    "X_train_final = selection.fit_transform(X_train_final, Y_train)\n",
    "X_test_final = selection.transform(X_test_final)\n",
    "\n",
    "gs_classifier = GridSearchCV(base_classifier, params, cv=5)\n",
    "gs_classifier.fit(X_train_final, Y_train)\n",
    "\n",
    "print(\"Validation accuracy: %0.6f\" % gs_classifier.best_score_)\n",
    "print(\"Test accuracy: %0.6f\" % accuracy_score(Y_test, gs_classifier.predict(X_test_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.810112\n",
      "Test accuracy: 0.727273\n"
     ]
    }
   ],
   "source": [
    "# Skip gram:for ngram (1,4)\n",
    "X_train_final = vect.fit_transform(features_skip(d, ngram_range=(1,4)) for d in text_train)\n",
    "X_test_final = vect.transform(features_skip(d, ngram_range=(1,4)) for d in text_test)\n",
    "\n",
    "selection = SelectPercentile(percentile=per, score_func=chi2)\n",
    "X_train_final = selection.fit_transform(X_train_final, Y_train)\n",
    "X_test_final = selection.transform(X_test_final)\n",
    "\n",
    "gs_classifier = GridSearchCV(base_classifier, params, cv=5)\n",
    "gs_classifier.fit(X_train_final, Y_train)\n",
    "\n",
    "print(\"Validation accuracy: %0.6f\" % gs_classifier.best_score_)\n",
    "print(\"Test accuracy: %0.6f\" % accuracy_score(Y_test, gs_classifier.predict(X_test_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word pairs\n",
    "def features_pairs(text):\n",
    "    text = text.lower()      # make the string lowercase\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)     # remove consecutive characters that are repeated more than twice\n",
    "    \n",
    "    features_in_text = []   # running list of all features in this instance (can be repeated)\n",
    "    \n",
    "    # treat alphanumeric characters as word tokens (removing anything else),\n",
    "    # and extract all n-grams of length n specified by ngram_range\n",
    "    \n",
    "    text_alphanum = re.sub('[^a-z0-9]', ' ', text).split()\n",
    "\n",
    "    # look at word pairs\n",
    "    word_pairs = {}\n",
    "    for ind1, word_1 in enumerate(text_alphanum):\n",
    "        for ind2, word_2 in enumerate(text_alphanum[ind1+1:]):\n",
    "            srtd_word_pair = tuple(sorted([word_1, word_2]))\n",
    "            if ind2 == 0:\n",
    "                word_pairs[srtd_word_pair] = 1\n",
    "            #elif srtd_word_pair not in word_pairs:\n",
    "                #word_pairs[srtd_word_pair] = 0\n",
    "    \n",
    "    return word_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('is', 'this'): 1, ('an', 'is'): 1, ('an', 'example'): 1, ('example', 'of'): 1, ('a', 'of'): 1, ('a', 'sentence'): 1, ('sentence', 'to'): 1, ('to', 'tokenize'): 1, ('actually', 'tokenize'): 1, ('actually', 'it'): 1, ('it', 's'): 1, ('more', 's'): 1, ('more', 'than'): 1, ('a', 'than'): 1, ('it', 'sentence'): 1, ('s', 'two'): 1, ('sentences', 'two'): 1}\n"
     ]
    }
   ],
   "source": [
    "text = \"This is an example of a sentence to tokenize!! Actually, it's more than a sentence, it's two sentences!!!\"\n",
    "\n",
    "print(features_pairs(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.798876\n",
      "Test accuracy: 0.681818\n"
     ]
    }
   ],
   "source": [
    "# word pairs:\n",
    "X_train_final = vect.fit_transform(features_pairs(d,) for d in text_train)\n",
    "X_test_final = vect.transform(features_pairs(d,) for d in text_test)\n",
    "\n",
    "selection = SelectPercentile(percentile=per, score_func=chi2)\n",
    "X_train_final = selection.fit_transform(X_train_final, Y_train)\n",
    "X_test_final = selection.transform(X_test_final)\n",
    "\n",
    "gs_classifier = GridSearchCV(base_classifier, params, cv=5)\n",
    "gs_classifier.fit(X_train_final, Y_train)\n",
    "\n",
    "print(\"Validation accuracy: %0.6f\" % gs_classifier.best_score_)\n",
    "print(\"Test accuracy: %0.6f\" % accuracy_score(Y_test, gs_classifier.predict(X_test_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.773034\n",
      "Test accuracy: 0.690909\n"
     ]
    }
   ],
   "source": [
    "# word pairs control\n",
    "def features_pairs_control(text, ngram_range=(2,2)):\n",
    "    text = text.lower()      # make the string lowercase\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)     # remove consecutive characters that are repeated more than twice\n",
    "    \n",
    "    features_in_text = []   # running list of all features in this instance (can be repeated)\n",
    "    \n",
    "    # treat alphanumeric characters as word tokens (removing anything else),\n",
    "    # and extract all n-grams of length n specified by ngram_range\n",
    "    \n",
    "    text_alphanum = re.sub('[^a-z0-9]', ' ', text)\n",
    "    for n in range(ngram_range[0], ngram_range[1]+1):\n",
    "        features_in_text += ngrams(text_alphanum.split(), n)\n",
    "    \n",
    "    return Counter(features_in_text)\n",
    "\n",
    "X_train_final = vect.fit_transform(features_pairs_control(d,(2,2)) for d in text_train)\n",
    "X_test_final = vect.transform(features_pairs_control(d,(2,2)) for d in text_test)\n",
    "\n",
    "selection = SelectPercentile(percentile=per, score_func=chi2)\n",
    "X_train_final = selection.fit_transform(X_train_final, Y_train)\n",
    "X_test_final = selection.transform(X_test_final)\n",
    "\n",
    "gs_classifier = GridSearchCV(base_classifier, params, cv=5)\n",
    "gs_classifier.fit(X_train_final, Y_train)\n",
    "\n",
    "print(\"Validation accuracy: %0.6f\" % gs_classifier.best_score_)\n",
    "print(\"Test accuracy: %0.6f\" % accuracy_score(Y_test, gs_classifier.predict(X_test_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_sentiment(text, ngram_range=(1,1)):\n",
    "    text = text.lower()      # make the string lowercase\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)     # remove consecutive characters that are repeated more than twice\n",
    "    \n",
    "    features_in_text = []   # running list of all features in this instance (can be repeated)\n",
    "    \n",
    "    # treat alphanumeric characters as word tokens (removing anything else),\n",
    "    # and extract all n-grams of length n specified by ngram_range\n",
    "    \n",
    "    text_alphanum = re.sub('[^a-z0-9]', ' ', text)\n",
    "    for n in range(ngram_range[0], ngram_range[1]+1):\n",
    "        features_in_text += ngrams(text_alphanum.split(), n)\n",
    "        \n",
    "    for ngram in features_in_text:\n",
    "        tmp_ngram = ngram.split()\n",
    "        for ind, word in enumerate(tmp_ngram):\n",
    "            if word in positive_words:\n",
    "                tmp_ngram[ind] = \"POS\"\n",
    "            elif word in negative_words:\n",
    "                tmp_ngram[ind] = \"NEG\"\n",
    "        # turn list into string\n",
    "        tmp_ngram = ' '.join(tmp_ngram)\n",
    "        if tmp_ngram != ngram:\n",
    "            features_in_text.append(tmp_ngram)\n",
    "        \n",
    "    \n",
    "    # now treat punctuation as word tokens, and get their counts (only unigrams)\n",
    "    \n",
    "    text_punc = re.sub('[a-z0-9]', ' ', text)\n",
    "    features_in_text += ngrams(text_punc.split(), 1)\n",
    "    \n",
    "    # 'Counter' converts a list into a dictionary whose keys are the list elements \n",
    "    #  and the values are the number of times each element appeared in the list\n",
    "    \n",
    "    return Counter(features_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the water': 1, 'water is': 1, 'is cold': 1, 'is NEG': 1, '.': 1})\n"
     ]
    }
   ],
   "source": [
    "text = \"The water is cold.\"\n",
    "\n",
    "print(features_sentiment(text, ngram_range=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for 2.1-2.2 here\n",
    "\n",
    "# You should be able to use the code below as-is, except replace the call to the \"features\" function \n",
    "# in the first two lines with a call to the new function that you need to create\n",
    "\n",
    "X_train_final = vect.fit_transform(features_sentiment(d, ngram_range=ngr) for d in text_train)\n",
    "X_test_final = vect.transform(features_sentiment(d, ngram_range=ngr) for d in text_test)\n",
    "\n",
    "selection = SelectPercentile(percentile=per, score_func=chi2)\n",
    "X_train_final = selection.fit_transform(X_train_final, Y_train)\n",
    "X_test_final = selection.transform(X_test_final)\n",
    "\n",
    "gs_classifier = GridSearchCV(base_classifier, params, cv=5)\n",
    "gs_classifier.fit(X_train_final, Y_train)\n",
    "\n",
    "print(\"Validation accuracy: %0.6f\" % gs_classifier.best_score_)\n",
    "print(\"Test accuracy: %0.6f\" % accuracy_score(Y_test, gs_classifier.predict(X_test_final)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
